//-------------------------------------------------------------------------------------------------------
// Copyright (C) Microsoft. All rights reserved.
// Licensed under the MIT license. See LICENSE.txt file in the project root for full license information.
//-------------------------------------------------------------------------------------------------------
#pragma once


//This file contains definitions for general-ish purpose structures/algorithms that we use in the TTD system 
//We may want to replace them with other versions (e.g. that are already in the codebase) at some later time

#if ENABLE_TTD

//2MB slabs in allocator with a threshold of 4Kb to allocate a single block in our large space
#define TTD_SLAB_BLOCK_ALLOCATION_SIZE 2097152
#define TTD_SLAB_LARGE_BLOCK_SIZE 4096
#define TTD_WORD_ALIGN_ALLOC_SIZE(ASIZE) (((ASIZE) + 0x3) & 0xFFFFFFFC)

#define TTD_SLAB_BLOCK_SIZE TTD_WORD_ALIGN_ALLOC_SIZE(sizeof(SlabBlock))
#define TTD_SLAB_BLOCK_USABLE_SIZE (TTD_SLAB_BLOCK_ALLOCATION_SIZE - TTD_SLAB_BLOCK_SIZE)

#define TTD_LARGE_SLAB_BLOCK_SIZE TTD_WORD_ALIGN_ALLOC_SIZE(sizeof(LargeSlabBlock))

//allocation increments for the array list -- we pick sizes that are just larger than the number generated by a "simple" programs

#define TTD_ARRAY_LIST_SIZE_LARGE 4096
#define TTD_ARRAY_LIST_SIZE_DEFAULT 2048
#define TTD_ARRAY_LIST_SIZE_SMALL 32

//
//We are assuming a 4GB pointer address space here (starting at 0) so we probably want to revisit this when we add better GC support
//

//Sizes for each of the layers in the mark table
#define TTD_OFFSETS_PER_PAGE 4194304
#define TTD_PAGES_PER_REGION 1048576
#define TTD_REGIONS_PER_HEAP 1048576

#define TTD_OBJECT_ALIGNMENT_MASK 0x3

//How to get the index values for each level in the table + how to get the upper addr for our simple cache
#define TTD_MARK_GET_OFFSET(X) ((X >> 2) & 0x3FFFFF)
#define TTD_MARK_GET_PAGE(X) ((X >> 24) & 0xFFFFF)
#define TTD_MARK_GET_REGION(X) (X >> 44)

#define TTD_REBUILD_ADDR(REGION, PAGE, OFFSET) ((REGION << 44) | (PAGE << 24) | (OFFSET << 2))

//A basic universal hash function for our dictionary
#define TTD_DICTIONARY_LOAD_FACTOR 2
#define TTD_DICTIONARY_HASH(X, P) ((uint32)(X % P))
#define TTD_DICTIONARY_INDEX(X, M) ((uint32)(X & (M - 1)))

namespace TTD
{
    //Function pointer definitions and a struct for writing data out of memory (presumably to stable storage)
    typedef bool(CALLBACK *TTDDbgCallback)(INT64* optEventTimeRequest, wchar_t** optStaticRequestMessage);

    typedef void(CALLBACK *TTDInitializeTTDUriCallback)(const wchar_t* uri, wchar_t** fullTTDUri);
    typedef void(CALLBACK *TTDInitializeForWriteLogStreamCallback)(const wchar_t* uri);
    typedef HANDLE(CALLBACK *TTDGetLogStreamCallback)(const wchar_t* uri, bool read, bool write);
    typedef HANDLE(CALLBACK *TTDGetSnapshotStreamCallback)(const wchar_t* logRootUri, const wchar_t* snapId, bool read, bool write, wchar_t** snapContainerUri);
    typedef HANDLE(CALLBACK *TTDGetSrcCodeStreamCallback)(const wchar_t* snapContainerUri, const wchar_t* documentid, const wchar_t* srcFileName, bool read, bool write);

    typedef BOOL(CALLBACK *TTDReadBytesFromStreamCallback)(HANDLE strm, BYTE* buff, DWORD size, DWORD* readCount);
    typedef BOOL(CALLBACK *TTDWriteBytesToStreamCallback)(HANDLE strm, BYTE* buff, DWORD size, DWORD* writtenCount);
    typedef void(CALLBACK *TTDFlushAndCloseStreamCallback)(HANDLE strm, bool read, bool write);

    struct IOStreamFunctions
    {
        TTDGetLogStreamCallback pfGetLogStream;
        TTDGetSnapshotStreamCallback pfGetSnapshotStream;
        TTDGetSrcCodeStreamCallback pfGetSrcCodeStream;

        TTDReadBytesFromStreamCallback pfReadBytesFromStream;
        TTDWriteBytesToStreamCallback pfWriteBytesToStream;
        TTDFlushAndCloseStreamCallback pfFlushAndCloseStream;
    };

    namespace UtilSupport
    {
        //A basic auto-managed string with value semantics
        class TTAutoString
        {
        private:
            int32 m_allocSize;
            wchar* m_contents;
            wchar* m_optFormatBuff;

        public:
            TTAutoString();
            TTAutoString(LPCWSTR str);
            TTAutoString(const TTAutoString& str);
            TTAutoString(TTAutoString&& str);
            ~TTAutoString();

            void Clear();

            TTAutoString& operator=(const TTAutoString& str);
            TTAutoString& operator=(TTAutoString&& str);

            bool IsNullString() const;

            void Append(LPCWSTR str, int32 start = 0, int32 end = INT32_MAX);
            void Append(const TTAutoString& str, int32 start = 0, int32 end = INT32_MAX);

            void Append(uint64 val);

            void Append(LPCUTF8 strBegin, LPCUTF8 strEnd);

            int32 GetLength() const;
            wchar GetCharAt(int32 pos) const;
            LPCWSTR GetStrValue() const;
        };
    }

    //////////////////

    //A class that implements a simple slab memory allocator
    template <int32 canUnlink>
    class SlabAllocatorBase
    {
    private:
        //A block that the slab allocator uses
        struct SlabBlock
        {
            //The actual block for the data -- should be laid out immediately after this
            byte* BlockData;

            //The previous/next block in the list
            SlabBlock* Previous;
            SlabBlock* Next;

            //The reference counter for this -- invalid if canUnlink == 0
            int32 RefCounter;
        };

        //A "large" block allocation list
        struct LargeSlabBlock
        {
            //The actual block for the data -- should be laid out immediately after this
            byte* BlockData;

            //The size of the block in bytes (includes both LargeSlabBlock and data memory)
            uint32 TotalBlockSize;

            //The previous/next block in the list
            LargeSlabBlock* Previous;
            LargeSlabBlock* Next;

            //Place well known meta-data ptr here (nullptr) so we know it is a large block (not a regular slab alloc).
            void* MetaDataSential;
        };

        //We inline the fields for the current/end of the block that we currently are allocating from a
        byte* m_currPos;
        byte* m_endPos;

        //The list of slab blocks used in the allocator (the current block to allocate from is always at the head)
        SlabBlock* m_headBlock;

        //The large allocation list
        LargeSlabBlock* m_largeBlockList;

#if ENABLE_TTD_INTERNAL_DIAGNOSTICS
        //The amount of allocated memory with useful data
        uint64 m_totalAllocatedSize;

        //Make sure we don't double allocate anything
        uint32 m_reserveActive;
#endif

        //Get a new block in the slab
        void AddNewBlock()
        {
            byte* allocBlock = HeapNewArray(byte, TTD_SLAB_BLOCK_ALLOCATION_SIZE);
            AssertMsg((reinterpret_cast<uint64>(allocBlock) & 0x3) == 0, "We have non-word aligned allocations so all our later work is not so useful");

            SlabBlock* newBlock = (SlabBlock*)allocBlock;
            byte* dataArray = (allocBlock + TTD_SLAB_BLOCK_SIZE);

            this->m_currPos = dataArray;
            this->m_endPos = dataArray + TTD_SLAB_BLOCK_USABLE_SIZE;

            newBlock->BlockData = dataArray;
            newBlock->Next = nullptr;
            newBlock->Previous = this->m_headBlock;
            newBlock->RefCounter = 0;

            this->m_headBlock->Next = newBlock;
            this->m_headBlock = newBlock;
        }

        //Allocate a byte* of the the template size (word aligned)
        template <size_t n>
        byte* SlabAllocateTypeRawSize()
        {
#if ENABLE_TTD_INTERNAL_DIAGNOSTICS
            AssertMsg(this->m_reserveActive == 0, "Don't double allocate memory.");
#endif
            AssertMsg(n <= TTD_SLAB_LARGE_BLOCK_SIZE, "Don't allocate large requests in the bump pool.");

            uint32 desiredsize = TTD_WORD_ALIGN_ALLOC_SIZE(n + canUnlink); //make alloc size word aligned
            AssertMsg((desiredsize % 4 == 0) & (desiredsize >= (n + canUnlink)) & (desiredsize < TTD_SLAB_BLOCK_ALLOCATION_SIZE), "We can never allocate a block this big with the slab allocator!!");

            if(this->m_currPos + desiredsize > this->m_endPos)
            {
                this->AddNewBlock();
            }

            byte* res = this->m_currPos;
            this->m_currPos += desiredsize;

#if ENABLE_TTD_INTERNAL_DIAGNOSTICS
            this->m_totalAllocatedSize += TTD_WORD_ALIGN_ALLOC_SIZE(n);
#endif

            if(canUnlink)
            {
                AssertMsg(canUnlink == sizeof(SlabBlock*), "We need enough space for a ptr to the meta-data.");

                //record the block associated with this allocation
                *((SlabBlock**)res) = this->m_headBlock;
                res += canUnlink;

                //update the ctr for this block
                this->m_headBlock->RefCounter++;
            }

            return res;
        }

        //Allocate a byte* of the the given size (word aligned)
        template <bool reserve, bool commit>
        byte* SlabAllocateRawSize(size_t requestedBytes)
        {
            AssertMsg(requestedBytes != 0, "Don't allocate empty arrays.");
            AssertMsg(requestedBytes <= TTD_SLAB_LARGE_BLOCK_SIZE, "Don't allocate large requests in the bump pool.");

            byte* res = nullptr;
            uint32 desiredsize = TTD_WORD_ALIGN_ALLOC_SIZE(requestedBytes + canUnlink); //make alloc size word aligned
            AssertMsg((desiredsize % 4 == 0) & (desiredsize >= (requestedBytes + canUnlink)) & (desiredsize < TTD_SLAB_BLOCK_ALLOCATION_SIZE), "We can never allocate a block this big with the slab allocator!!");

            if(reserve)
            {
#if ENABLE_TTD_INTERNAL_DIAGNOSTICS
                AssertMsg(this->m_reserveActive == 0, "Don't double allocate memory.");
#endif

                if(this->m_currPos + desiredsize > this->m_endPos)
                {
                    this->AddNewBlock();
                }

                res = this->m_currPos;

                if(canUnlink)
                {
                    AssertMsg(canUnlink == sizeof(SlabBlock*), "We need enough space for a ptr to the meta-data.");

                    //record the block associated with this allocation
                    *((SlabBlock**)res) = this->m_headBlock;
                    res += canUnlink;
                }
            }

            if(commit)
            {
                this->m_currPos += desiredsize;

#if ENABLE_TTD_INTERNAL_DIAGNOSTICS
                this->m_totalAllocatedSize += TTD_WORD_ALIGN_ALLOC_SIZE(requestedBytes);
#endif

                if(canUnlink)
                {
                    this->m_headBlock->RefCounter++;
                }
            }

#if ENABLE_TTD_INTERNAL_DIAGNOSTICS
            if(reserve & !commit)
            {
                this->m_reserveActive = desiredsize;
            }

            if(!reserve & commit)
            {
                AssertMsg(desiredsize <= this->m_reserveActive, "We are commiting more that we reserved.");

                this->m_reserveActive = 0;
            }
#endif

            return res;
        }

        //Allocate a byte* of the the given size (word aligned) in the large block pool
        byte* SlabAllocateLargeBlockSize(size_t requestedBytes)
        {
            AssertMsg(requestedBytes > TTD_SLAB_LARGE_BLOCK_SIZE, "Don't allocate small requests in the large pool.");

            uint32 desiredsize = TTD_WORD_ALIGN_ALLOC_SIZE(requestedBytes + TTD_LARGE_SLAB_BLOCK_SIZE); //make alloc size word aligned
            AssertMsg((desiredsize % 4 == 0) & (desiredsize >= (requestedBytes + TTD_LARGE_SLAB_BLOCK_SIZE)), "We can never allocate a block this big with the slab allocator!!");

#if ENABLE_TTD_INTERNAL_DIAGNOSTICS
            AssertMsg(this->m_reserveActive == 0, "Don't double allocate memory.");
#endif

            byte* tmp = HeapNewArray(byte, desiredsize);

            LargeSlabBlock* newBlock = (LargeSlabBlock*)tmp;
            newBlock->BlockData = (tmp + TTD_LARGE_SLAB_BLOCK_SIZE);

            newBlock->TotalBlockSize = desiredsize;
            newBlock->Previous = this->m_largeBlockList;
            newBlock->Next = nullptr;

            newBlock->MetaDataSential = nullptr;

            if(this->m_largeBlockList != nullptr)
            {
                this->m_largeBlockList->Next = newBlock;
            }

            this->m_largeBlockList = newBlock;

#if ENABLE_TTD_INTERNAL_DIAGNOSTICS
            this->m_totalAllocatedSize += TTD_WORD_ALIGN_ALLOC_SIZE(requestedBytes);
#endif

            return this->m_largeBlockList->BlockData;
        }

    public:
        SlabAllocatorBase()
            : m_largeBlockList(nullptr)
        {
            byte* allocBlock = HeapNewArray(byte, TTD_SLAB_BLOCK_ALLOCATION_SIZE);
            AssertMsg((reinterpret_cast<uint64>(allocBlock) & 0x3) == 0, "We have non-word aligned allocations so all our later work is not so useful");

            this->m_headBlock = (SlabBlock*)allocBlock;
            byte* dataArray = (allocBlock + TTD_SLAB_BLOCK_SIZE);

            this->m_currPos = dataArray;
            this->m_endPos = dataArray + TTD_SLAB_BLOCK_USABLE_SIZE;

            this->m_headBlock->BlockData = dataArray;

            this->m_headBlock->Next = nullptr;
            this->m_headBlock->Previous = nullptr;

            this->m_headBlock->RefCounter = 0;

#if ENABLE_TTD_INTERNAL_DIAGNOSTICS
            this->m_totalAllocatedSize = 0;
            this->m_reserveActive = 0;
#endif
        }

        ~SlabAllocatorBase()
        {
            SlabBlock* currBlock = this->m_headBlock;
            while(currBlock != nullptr)
            {
                SlabBlock* tmp = currBlock;
                currBlock = currBlock->Previous;

                HeapDeleteArray(TTD_SLAB_BLOCK_ALLOCATION_SIZE, (byte*)tmp);
            }

            LargeSlabBlock* currLargeBlock = this->m_largeBlockList;
            while(currLargeBlock != nullptr)
            {
                LargeSlabBlock* tmp = currLargeBlock;
                currLargeBlock = currLargeBlock->Previous;

                HeapDeleteArray(tmp->TotalBlockSize, (byte*)tmp);
            }
        }

        //eliminate some potentially dangerous operators
        SlabAllocatorBase(const SlabAllocatorBase&) = delete;
        SlabAllocatorBase& operator=(SlabAllocatorBase const&) = delete;

        //clone a string into the allocator
        LPCWSTR CopyStringInto(LPCWSTR str)
        {
            size_t byteLen = (wcslen(str) + 1) * sizeof(wchar_t);
            wchar_t* copystr = (wchar_t*)this->SlabAllocateArray<byte>(byteLen);
            memcpy(copystr, str, byteLen);

            return copystr;
        }

        //Return the memory that contains useful data in this slab & the same as the reserved space
        void ComputeMemoryUsed(uint64* usedSpace, uint64* reservedSpace) const
        {
            uint64 memreserved = 0;

            for(SlabBlock* currBlock = this->m_headBlock; currBlock != nullptr; currBlock = currBlock->Previous)
            {
                memreserved += (uint64)TTD_SLAB_BLOCK_ALLOCATION_SIZE;
            }

            for(LargeSlabBlock* currLargeBlock = this->m_largeBlockList; currLargeBlock != nullptr; currLargeBlock = currLargeBlock->Previous)
            {
                memreserved += (uint64)(currLargeBlock->TotalBlockSize);
            }

#if ENABLE_TTD_INTERNAL_DIAGNOSTICS
            *usedSpace = this->m_totalAllocatedSize;
#else
            *usedSpace = 0;
#endif

            *reservedSpace = memreserved;
        }

        //Allocate with "new" from the slab allocator
        template<typename T, typename... Args>
        T* SlabNew(Args... args)
        {
            return new (this->SlabAllocateTypeRawSize<sizeof(T)>()) T(args...);
        }

        template <typename T>
        void SlabDelete(T* obj)
        {
            obj->~T();

            if(canUnlink != 0)
            {
                this->UnlinkAllocation(obj);
            }
        }

        //Allocate a T* of the size needed for the template type
        template <typename T>
        T* SlabAllocateStruct()
        {
            return (T*)this->SlabAllocateTypeRawSize<sizeof(T)>();
        }

        //Allocate T* of the size needed to hold count elements of the given type
        template <typename T>
        T* SlabAllocateArray(size_t count)
        {
            size_t size = count * sizeof(T);
            if(size <= TTD_SLAB_LARGE_BLOCK_SIZE)
            {
                return (T*)this->SlabAllocateRawSize<true, true>(size);
            }
            else
            {
                return (T*)this->SlabAllocateLargeBlockSize(size);
            }
        }

        //Allocate T* of the size needed to hold count elements of the given type
        template <typename T>
        T* SlabAllocateArrayZ(size_t count)
        {
            T* res = nullptr;

            size_t size = count * sizeof(T);
            if(size <= TTD_SLAB_LARGE_BLOCK_SIZE)
            {
                res = (T*)this->SlabAllocateRawSize<true, true>(size);
            }
            else
            {
                res = (T*)this->SlabAllocateLargeBlockSize(size);
            }

            memset(res, 0, size);
            return res;
        }

        //Allocate T* of the size needed to hold count (a compile time constant) number of elements of the given type
        template <typename T, size_t count>
        T* SlabAllocateFixedSizeArray()
        {
            if(count * sizeof(T) <= TTD_SLAB_LARGE_BLOCK_SIZE)
            {
                return (T*)this->SlabAllocateRawSize<true, true>(count * sizeof(T));
            }
            else
            {
                return (T*)this->SlabAllocateLargeBlockSize(count * sizeof(T));
            }
        }

        //Reserve BUT DO NOT COMMIT and allocation of size needed to hold count elements of the given type
        template <typename T>
        T* SlabReserveArraySpace(size_t count)
        {
            size_t size = count * sizeof(T);
            if(size <= TTD_SLAB_LARGE_BLOCK_SIZE)
            {
                return (T*)this->SlabAllocateRawSize<true, false>(size);
            }
            else
            {
                return (T*)this->SlabAllocateLargeBlockSize(size);
            }
        }

        //Commit the allocation of count (or fewer) elements of the given type that were reserved previously
        template <typename T>
        void SlabCommitArraySpace(size_t count)
        {
            size_t size = count * sizeof(T);
            if(size <= TTD_SLAB_LARGE_BLOCK_SIZE)
            {
                this->SlabAllocateRawSize<false, true>(size);
            }
            //we always commit large allocs so no need to clear reserved count info
        }

        //Abort the allocation of the elements of the given type that were reserved previously
        template <typename T>
        void SlabAbortArraySpace()
        {
#if ENABLE_TTD_INTERNAL_DIAGNOSTICS
            AssertMsg(this->m_reserveActive != 0, "We don't have anything reserved.");
#endif

            this->m_reserveActive = 0;
        }

        //If allowed unlink the memory allocation specified and free the block if it is no longer used by anyone
        void UnlinkAllocation(void* allocation)
        {
            AssertMsg(canUnlink, "Unlink not allowed with this slab allocator.");
#if ENABLE_TTD_INTERNAL_DIAGNOSTICS
            AssertMsg(this->m_reserveActive != 0, "We don't have anything reserved.");
#endif

            //get the meta-data for this allocation and see if it is a 
            void* metadataPtr = (void*)(((byte*)allocation) - canUnlink);
            if(metadataPtr == nullptr)
            {
                //it is a large allocation just free it
                LargeSlabBlock* largeBlock = (LargeSlabBlock*)(((byte*)allocation) - TTD_LARGE_SLAB_BLOCK_SIZE);

                if(largeBlock->Next != nullptr)
                {
                    largeBlock->Next->Previous = largeBlock->Previous;
                }

                if(largeBlock->Previous != nullptr)
                {
                    largeBlock->Previous->Next = largeBlock->Next;
                }

                HeapDeleteArray(largeBlock->TotalBlockSize, (byte*)largeBlock);
            }
            else
            {
                //lookup the slab block and do ref counting
                SlabBlock* block = (SlabBlock*)(((byte*)allocation) - canUnlink);

                block->RefCounter--;
                if(block->RefCounter == 0)
                {
                    if(block == this->m_headBlock)
                    {
                        //we always need a head block to allocate out of -- so instead of deleting just reset it

                        this->m_currPos = this->m_headBlock->BlockData;
                        this->m_endPos = this->m_headBlock->BlockData + TTD_SLAB_BLOCK_USABLE_SIZE;

                        this->m_headBlock->RefCounter = 0;
                    }
                    else
                    {
                        if(block->Next != nullptr)
                        {
                            block->Next->Previous = block->Previous;
                        }

                        if(block->Previous != nullptr)
                        {
                            block->Previous->Next = block->Next;
                        }

                        HeapDeleteArray(TTD_SLAB_BLOCK_ALLOCATION_SIZE, (byte*)block);
                    }
                }
            }
        }
    };

    //The standard slab allocator implemention does not allow for unlinking
    typedef SlabAllocatorBase<0> SlabAllocator;

    //The unlinkable slab allocator implemention (as expected) allows for unlinking
    typedef SlabAllocatorBase<sizeof(void*)> UnlinkableSlabAllocator;

    //////////////////
    //An (unordered) array list class that has fast insertion/write-into and does not move contents

    template<typename T, size_t allocSize>
    class UnorderedArrayList
    {
    private:
        struct UnorderedArrayListLink
        {
            //The current end of the allocated data in the block
            T* CurrPos;

            //The last valid position in the block -- a little unusual but then the "alloc part does not depend on the outcome of the if condition"
            T* EndPos;

            //The actual block for the data
            T* BlockData;

            //The next block in the list
            UnorderedArrayListLink* Next;
        };

        //The the data in this
        UnorderedArrayListLink m_inlineHeadBlock;

        //the allocators we use for this work
        SlabAllocator* m_alloc;

        void AddArrayLink()
        {
            UnorderedArrayListLink* copiedOldBlock = this->m_alloc->SlabAllocateStruct<UnorderedArrayListLink>();
            *copiedOldBlock = this->m_inlineHeadBlock;

            T* newBlockData = this->m_alloc->SlabAllocateFixedSizeArray<T, allocSize>();

            this->m_inlineHeadBlock.BlockData = newBlockData;
            this->m_inlineHeadBlock.CurrPos = newBlockData;
            this->m_inlineHeadBlock.EndPos = newBlockData + allocSize;

            this->m_inlineHeadBlock.Next = copiedOldBlock;
        }

    public:
        UnorderedArrayList(SlabAllocator* alloc)
            : m_alloc(alloc)
        {
            T* newBlockData = this->m_alloc->SlabAllocateFixedSizeArray<T, allocSize>();

            this->m_inlineHeadBlock.BlockData = newBlockData;
            this->m_inlineHeadBlock.CurrPos = newBlockData;
            this->m_inlineHeadBlock.EndPos = newBlockData + allocSize;

            this->m_inlineHeadBlock.Next = nullptr;
        }

        ~UnorderedArrayList()
        {
            //everything is slab allocated so disapears with that
        }

        //Add the entry to the unordered list
        void AddEntry(T data)
        {
            AssertMsg(this->m_inlineHeadBlock.CurrPos <= this->m_inlineHeadBlock.EndPos, "We are off the end of the array");
            AssertMsg((((byte*)this->m_inlineHeadBlock.CurrPos) - ((byte*)this->m_inlineHeadBlock.BlockData)) / sizeof(T) <= allocSize, "We are off the end of the array");

            if(this->m_inlineHeadBlock.CurrPos == this->m_inlineHeadBlock.EndPos)
            {
                this->AddArrayLink();
            }

            *(this->m_inlineHeadBlock.CurrPos) = data;
            this->m_inlineHeadBlock.CurrPos++;
        }

        //Get the next uninitialized entry (at the front of the sequence)
        //We expect the caller to initialize this memory appropriately
        T* NextOpenEntry()
        {
            AssertMsg(this->m_inlineHeadBlock.CurrPos <= this->m_inlineHeadBlock.EndPos, "We are off the end of the array");
            AssertMsg((((byte*)this->m_inlineHeadBlock.CurrPos) - ((byte*)this->m_inlineHeadBlock.BlockData)) / sizeof(T) <= allocSize, "We are off the end of the array");

            if(this->m_inlineHeadBlock.CurrPos == this->m_inlineHeadBlock.EndPos)
            {
                this->AddArrayLink();
            }

            T* entry = this->m_inlineHeadBlock.CurrPos;
            this->m_inlineHeadBlock.CurrPos++;

            return entry;
        }

        //NOT constant time
        uint32 Count() const
        {
            size_t count = (((byte*)this->m_inlineHeadBlock.CurrPos) - ((byte*)this->m_inlineHeadBlock.BlockData)) / sizeof(T);
            AssertMsg(count <= allocSize, "We somehow wrote in too much data.");

            for(UnorderedArrayListLink* curr = this->m_inlineHeadBlock.Next; curr != nullptr; curr = curr->Next)
            {
                size_t ncount = (((byte*)curr->CurrPos) - ((byte*)curr->BlockData)) / sizeof(T);
                AssertMsg(ncount <= allocSize, "We somehow wrote in too much data.");

                count += ncount;
            }

            return (uint32)count;
        }

        class Iterator
        {
        private:
            UnorderedArrayListLink m_currLink;
            T* m_currEntry;

        public:
            Iterator(const UnorderedArrayListLink& head)
                : m_currLink(head), m_currEntry(head.BlockData)
            {
                //check for empty list and invalidate the iter if it is
                if(this->m_currEntry == this->m_currLink.CurrPos)
                {
                    this->m_currEntry = nullptr;
                }
            }

            const T* Current() const
            {
                return this->m_currEntry;
            }

            T* Current()
            {
                return this->m_currEntry;
            }

            bool IsValid() const
            {
                return this->m_currEntry != nullptr;
            }

            void MoveNext()
            {
                this->m_currEntry++;

                if(this->m_currEntry == this->m_currLink.CurrPos)
                {
                    if(this->m_currLink.Next == nullptr)
                    {
                        this->m_currEntry = nullptr;
                    }
                    else
                    {
                        this->m_currLink = *(this->m_currLink.Next);
                        this->m_currEntry = this->m_currLink.BlockData;
                    }
                }
            }
        };

        Iterator GetIterator() const
        {
            return Iterator(this->m_inlineHeadBlock);
        }
    };

    //////////////////
    //A specialized map for going from TTD_PTR_ID values to some information associated with them

    template <typename Tag, typename T>
    class TTDIdentifierDictionary
    {
    private:
        //An entry struct for the dictionary
        struct Entry
        {
            Tag Key;
            T Data;
        };

        //The 2 prime numbers we use for our hasing function
        uint32 m_h1Prime;
        uint32 m_h2Prime;

        //The hash max capcity and data array
        uint32 m_capacity;
        Entry* m_hashArray; 

        //Count of elements in the dictionary
        uint32 m_count;

        template <bool findEmpty>
        Entry* FindSlotForId(Tag id) const
        {
            AssertMsg(this->m_h1Prime != 0 && this->m_h2Prime != 0, "Not valid!!");
            AssertMsg(this->m_hashArray != nullptr, "Not valid!!");

            Tag searchKey = findEmpty ? 0 : id;

            //h1Prime is less than table size by construction so we dont need to re-index
            uint32 primaryIndex = TTD_DICTIONARY_HASH(id, this->m_h1Prime);
            if(this->m_hashArray[primaryIndex].Key == searchKey)
            {
                return (this->m_hashArray + primaryIndex);
            }

            //do a hash for the second offset to avoid clustering and then do linear probing
            uint32 offset = TTD_DICTIONARY_HASH(id, this->m_h2Prime);
            uint32 probeIndex = primaryIndex + offset;
            while(true)
            {
                Entry* curr = (this->m_hashArray + TTD_DICTIONARY_INDEX(probeIndex, this->m_capacity));
                if(curr->Key == searchKey)
                {
                    return curr;
                }
                probeIndex++;

                AssertMsg(TTD_DICTIONARY_INDEX(probeIndex, this->m_capacity) != TTD_DICTIONARY_INDEX(primaryIndex + offset, this->m_capacity), "The key is not here (or we messed up).");
            }
        }

        void InitializeEntry(Entry* entry, Tag id, const T& item)
        {
            entry->Key = id;
            entry->Data = item;
        }

    public:
        void Unload()
        {
            if(this->m_hashArray != nullptr)
            {
                HeapDeleteArray(this->m_capacity, this->m_hashArray);
                this->m_hashArray = nullptr;
                this->m_capacity = 0;

                this->m_count = 0;

                this->m_h1Prime = 0;
                this->m_h2Prime = 0;
            }
        }

        void Initialize(uint32 capacity)
        {
            AssertMsg(this->m_hashArray == nullptr, "Should not already be initialized.");

            uint32 desiredSize = capacity * TTD_DICTIONARY_LOAD_FACTOR;

            if(desiredSize < 128)
            {
                this->m_h1Prime = 127;
                this->m_h2Prime = 61;
                this->m_capacity = 128;
            }
            else if(desiredSize < 256)
            {
                this->m_h1Prime = 251;
                this->m_h2Prime = 127;
                this->m_capacity = 256;
            }
            else if(desiredSize < 512)
            {
                this->m_h1Prime = 511;
                this->m_h2Prime = 251;
                this->m_capacity = 512;
            }
            else if(desiredSize < 1024)
            {
                this->m_h1Prime = 1021;
                this->m_h2Prime = 509;
                this->m_capacity = 1024;
            }
            else if(desiredSize < 2048)
            {
                this->m_h1Prime = 2039;
                this->m_h2Prime = 1031;
                this->m_capacity = 2048;
            }
            else if(desiredSize < 4096)
            {
                this->m_h1Prime = 4093;
                this->m_h2Prime = 2039;
                this->m_capacity = 4096;
            }
            else if(desiredSize < 8192)
            {
                this->m_h1Prime = 8191;
                this->m_h2Prime = 4093;
                this->m_capacity = 8192;
            }
            else if(desiredSize < 16384)
            {
                this->m_h1Prime = 16381;
                this->m_h2Prime = 8191;
                this->m_capacity = 16384;
            }
            else if(desiredSize < 32768)
            {
                this->m_h1Prime = 32749;
                this->m_h2Prime = 16381;
                this->m_capacity = 32768;
            }
            else if(desiredSize < 65536)
            {
                this->m_h1Prime = 65521;
                this->m_h2Prime = 32749;
                this->m_capacity = 65536;
            }
            else if(desiredSize < 131072)
            {
                this->m_h1Prime = 131071;
                this->m_h2Prime = 65521;
                this->m_capacity = 131072;
            }
            else if(desiredSize < 262144)
            {
                this->m_h1Prime = 262139;
                this->m_h2Prime = 131071;
                this->m_capacity = 262144;
            }
            else if(desiredSize < 524288)
            {
                this->m_h1Prime = 524287;
                this->m_h2Prime = 262139;
                this->m_capacity = 524288;
            }
            else if(desiredSize < 1048576)
            {
                this->m_h1Prime = 1048573;
                this->m_h2Prime = 524287;
                this->m_capacity = 1048576;
            }
            else
            {
                AssertMsg(false, "That is a lot of objects -- we need to do some performance analysis.");

                this->m_h1Prime = 0;
                this->m_h2Prime = 0;
                this->m_capacity = 0;
            }

            this->m_hashArray = HeapNewArrayZ(Entry, this->m_capacity);
        }

        TTDIdentifierDictionary()
            : m_h1Prime(0), m_h2Prime(0), m_capacity(0), m_hashArray(nullptr), m_count(0)
        {
        }

        ~TTDIdentifierDictionary()
        {
            this->Unload();
        }

        void MoveDataInto(TTDIdentifierDictionary& src)
        {
            this->m_h1Prime = src.m_h1Prime;
            this->m_h2Prime = src.m_h2Prime;
            this->m_capacity = src.m_capacity;
            this->m_hashArray = src.m_hashArray;
            this->m_count = src.m_count;

            src.m_hashArray = HeapNewArrayZ(Entry, src.m_capacity);
            src.m_count = 0;
        }

        bool IsValid() const
        {
            return this->m_hashArray != nullptr;
        }

        uint32 Count() const
        {
            return this->m_count;
        }

        bool Contains(Tag id) const
        {
            AssertMsg(this->m_h1Prime != 0 && this->m_h2Prime != 0, "Not valid!!");
            AssertMsg(this->m_hashArray != nullptr, "Not valid!!");

            //h1Prime is less than table size by construction so we dont need to re-index
            uint32 primaryIndex = TTD_DICTIONARY_HASH(id, this->m_h1Prime);
            if(this->m_hashArray[primaryIndex].Key == id)
            {
                return true;
            }

            if(this->m_hashArray[primaryIndex].Key == 0)
            {
                return false;
            }

            //do a hash for the second offset to avoid clustering and then do linear probing
            uint32 offset = TTD_DICTIONARY_HASH(id, this->m_h2Prime);
            uint32 probeIndex = primaryIndex + offset;
            while(true)
            {
                Entry* curr = (this->m_hashArray + TTD_DICTIONARY_INDEX(probeIndex, this->m_capacity));
                if(curr->Key == id)
                {
                    return true;
                }

                if(curr->Key == 0)
                {
                    return false;
                }

                probeIndex++;

                AssertMsg(TTD_DICTIONARY_INDEX(probeIndex, this->m_capacity) != TTD_DICTIONARY_INDEX(primaryIndex + offset, this->m_capacity), "The key is not here (or we messed up).");
            }
        }

        void AddItem(TTD_PTR_ID ptrId, const T& item)
        {
            Entry* entry = this->FindSlotForId<true>(ptrId);

            InitializeEntry(entry, ptrId, item);
            this->m_count++;
        }

        //Lookup an item which is known to exist in the dictionary (and errors if it is not present)
        const T& LookupKnownItem(TTD_PTR_ID ptrId) const
        {
            Entry* entry = this->FindSlotForId<false>(ptrId);

            return entry->Data;
        }
    };

    //////////////////
    //A simple table to do object marking

    //
    //TODO: This table isn't great performance wise (around 2/3 of the time for a snapshot is spent in the mark-phase)
    //      Right now perf. isn't a limiting factor but we probably want to improve on this.
    //

    //Mark the table and what kind of value is at the address
    enum class MarkTableTag : byte
    {
        Clear = 0x0,
        //
        TypeHandlerTag = 0x1,
        TypeTag = 0x2,
        PrimitiveObjectTag = 0x3,
        CompoundObjectTag = 0x4,
        FunctionBodyTag = 0x5,
        EnvironmentTag = 0x6,
        SlotArrayTag = 0x7,
        KindTagCount = 0x8,
        AllKindMask = 0xF,
        //
        JsWellKnownObj = 0x10, //mark for objects that the JS runtime creates and are well known (Array, Undefined, ...)
        LogTaggedObj = 0x20, //mark for objects that are log tagged
        SpecialTagMask = 0xF0
    };
    DEFINE_ENUM_FLAG_OPERATORS(MarkTableTag);

    //3 level table of tags (regions -> pages -> tags)
    typedef MarkTableTag** MarkRegion;
    typedef MarkTableTag* MarkPage;

    class MarkTable
    {
    private:

        struct MarkIterator
        {
            uint32 m_currRegionIdx;
            uint32 m_currPageIdx;

            MarkTableTag* m_currBaseOffset;
            MarkTableTag* m_currOffset;
            MarkTableTag* m_currOffsetEnd;
        };

        MarkRegion* m_markHeap;

        //Iterator for this mark table (only 1 allowed at a time)
        MarkIterator m_iter;

        //Counts of how many handlers/types/... we have marked
        uint32 m_handlerCounts[(uint32)MarkTableTag::KindTagCount];

        const MarkTableTag* GetMarkPageForAddrNoCreate(uint64 addr) const
        {
            uint32 regionAddr = TTD_MARK_GET_REGION(addr);
            uint32 pageAddr = TTD_MARK_GET_PAGE(addr);

            AssertMsg((regionAddr < TTD_REGIONS_PER_HEAP) & (pageAddr < TTD_PAGES_PER_REGION), "We have a problem with our address space or bit masking!!");
            AssertMsg((this->m_markHeap[regionAddr] != nullptr) & (this->m_markHeap[regionAddr][pageAddr] != nullptr), "Missing a page");

            return this->m_markHeap[regionAddr][pageAddr];
        }

        MarkTableTag* GetMarkPageForAddrNoCreate(uint64 addr)
        {
            uint32 regionAddr = TTD_MARK_GET_REGION(addr);
            uint32 pageAddr = TTD_MARK_GET_PAGE(addr);

            AssertMsg((regionAddr < TTD_REGIONS_PER_HEAP) & (pageAddr < TTD_PAGES_PER_REGION), "We have a problem with our address space or bit masking!!");
            AssertMsg((this->m_markHeap[regionAddr] != nullptr) & (this->m_markHeap[regionAddr][pageAddr] != nullptr), "Missing a page");

            return this->m_markHeap[regionAddr][pageAddr];
        }

        MarkTableTag* GetMarkPageForAddrWithCreate(uint64 addr)
        {
            uint32 regionAddr = TTD_MARK_GET_REGION(addr);
            uint32 pageAddr = TTD_MARK_GET_PAGE(addr);

            AssertMsg((regionAddr < TTD_REGIONS_PER_HEAP) & (pageAddr < TTD_PAGES_PER_REGION), "We have a problem with our address space or bit masking!!");

            MarkRegion* regionPtr = (this->m_markHeap + regionAddr);
            if(*regionPtr == nullptr)
            {
                *regionPtr = HeapNewArrayZ(MarkTableTag*, TTD_PAGES_PER_REGION);
            }

            MarkPage* pagePtr = (*regionPtr + pageAddr);
            if(*pagePtr == nullptr)
            {
                *pagePtr = HeapNewArrayZ(MarkTableTag, TTD_OFFSETS_PER_PAGE);
            }

            return *pagePtr;
        }

    public:
        MarkTable();
        ~MarkTable();

        void Clear();

        //Check if the address has the given tag (return true if it *DOES NOT*) and put the mark tag value in the location
        template <MarkTableTag kindtag>
        bool MarkAndTestAddr(const void* vaddr)
        {
            AssertMsg((reinterpret_cast<uint64>(vaddr) & TTD_OBJECT_ALIGNMENT_MASK) == 0, "Not word aligned!!");
            AssertMsg(TTD_REBUILD_ADDR(TTD_MARK_GET_REGION(reinterpret_cast<uint64>(vaddr)), TTD_MARK_GET_PAGE(reinterpret_cast<uint64>(vaddr)), TTD_MARK_GET_OFFSET(reinterpret_cast<uint64>(vaddr))) == reinterpret_cast<uint64>(vaddr), "Lost some bits in the address.");

            MarkTableTag* page = this->GetMarkPageForAddrWithCreate(reinterpret_cast<uint64>(vaddr));

            uint32 offset = TTD_MARK_GET_OFFSET(reinterpret_cast<uint64>(vaddr));
            AssertMsg(offset < TTD_OFFSETS_PER_PAGE, "We are writing off the end of the page");
            AssertMsg((page[offset] & MarkTableTag::JsWellKnownObj) == MarkTableTag::Clear, "We are supposed to rundown mark after live marking.");

            bool notMarked = page[offset] == MarkTableTag::Clear;
            if(notMarked)
            {
                page[offset] = kindtag;
                (this->m_handlerCounts[(uint32)kindtag])++;
            }
            AssertMsg(page[offset] == kindtag, "We had some sort of collision.");

            return notMarked;
        }

        //Mark the address as containing a well known object of the given kind
        template <MarkTableTag specialtag>
        void MarkAddrWithSpecialInfo(const void* vaddr)
        {
            AssertMsg((reinterpret_cast<uint64>(vaddr) & TTD_OBJECT_ALIGNMENT_MASK) == 0, "Not word aligned!!");
            AssertMsg(TTD_REBUILD_ADDR(TTD_MARK_GET_REGION(reinterpret_cast<uint64>(vaddr)), TTD_MARK_GET_PAGE(reinterpret_cast<uint64>(vaddr)), TTD_MARK_GET_OFFSET(reinterpret_cast<uint64>(vaddr))) == reinterpret_cast<uint64>(vaddr), "Lost some bits in the address.");

            MarkTableTag* page = this->GetMarkPageForAddrNoCreate(reinterpret_cast<uint64>(vaddr));

            if(page != nullptr)
            {
                uint32 offset = TTD_MARK_GET_OFFSET(reinterpret_cast<uint64>(vaddr));
                AssertMsg(offset < TTD_OFFSETS_PER_PAGE, "We are writing off the end of the page");

                page[offset] |= specialtag;
            }
        }

        //Return true if the location is marked and if it is tagged as well-known
        bool IsMarked(const void* vaddr) const;
        bool IsTaggedAsWellKnown(const void* vaddr) const;

        //return clear if no more addresses
        MarkTableTag GetTagValue() const;
        bool GetTagValueIsWellKnown() const;
        bool GetTagValueIsLogged() const;

        template<typename T>
        T GetPtrValue() const
        {
            uint64 offset = (this->m_iter.m_currOffset - this->m_iter.m_currBaseOffset);
            uint64 addr = TTD_REBUILD_ADDR((uint64)this->m_iter.m_currRegionIdx, (uint64)this->m_iter.m_currPageIdx, offset);

            AssertMsg(this->m_iter.m_currRegionIdx < TTD_REGIONS_PER_HEAP && this->m_iter.m_currPageIdx < TTD_PAGES_PER_REGION && offset < TTD_OFFSETS_PER_PAGE, "This address does not exist!!!");

            return reinterpret_cast<T>(addr);
        }

        //Clear the mark at the given address
        void ClearMark(const void* vaddr);

        template <MarkTableTag kindtag>
        uint32 GetCountForTag()
        {
            return this->m_handlerCounts[(uint32)kindtag];
        }

        template<bool advance>
        bool MoveToNextMark()
        {
            if(advance)
            {
                //advance at least one position
                this->m_iter.m_currOffset++;
            }

            while(this->m_iter.m_currOffset < this->m_iter.m_currOffsetEnd)
            {
                MarkTableTag tag = *(this->m_iter.m_currOffset);
                if((tag & MarkTableTag::AllKindMask) != MarkTableTag::Clear)
                {
                    return true;
                }
                this->m_iter.m_currOffset++;
            }

            return false;
        }

        void MoveToNextAddressSlow();

        void MoveToNextAddress()
        {
            //usual case just walk to next mark
            bool foundMark = this->MoveToNextMark<true>();
            if(foundMark)
            {
                return;
            }

            this->MoveToNextAddressSlow();
        }

        void InitializeIter();
        void SetIterInvalid();
    };
}

#endif
